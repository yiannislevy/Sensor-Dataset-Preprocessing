{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.491157Z",
     "start_time": "2023-11-12T22:22:11.439485Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from src.main.mando_preprocessing import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "9f693cadaea4a1ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.512589Z",
     "start_time": "2023-11-12T22:22:11.443166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "6f32df3187369b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.513780Z",
     "start_time": "2023-11-12T22:22:11.447159Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # Find the weight file in the directory\n",
    "    files = [f for f in os.listdir(path) if f.startswith('weights_') and f.endswith('.txt')]\n",
    "    if not files:\n",
    "        raise ValueError(f\"No weight files found in directory: {path}\")\n",
    "    # We assume there's only one file matching the pattern, hence we take the first one\n",
    "    file_path = os.path.join(path, files[0])\n",
    "    # Load the data using pandas\n",
    "    weights = pd.read_csv(file_path, header=None, names=['weight'])\n",
    "    return weights['weight']\n",
    "\n",
    "# The rest of the script remains the same, you just need to call this function in the main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "a74a426cf659acfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.526978Z",
     "start_time": "2023-11-12T22:22:11.450599Z"
    }
   },
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    \"\"\"Calculate the moving average of the given data using a window of specified size.\"\"\"\n",
    "    cumsum_vec = np.cumsum(np.insert(data, 0, 0)) \n",
    "    return (cumsum_vec[window_size:] - cumsum_vec[:-window_size]) / window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "b1925fdc16710aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.530023Z",
     "start_time": "2023-11-12T22:22:11.454508Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_decreasing_curve(data):\n",
    "    \"\"\"Ensure that the data only decreases or stays constant over time to represent only food consumption.\"\"\"\n",
    "    decreased_data = np.copy(data)\n",
    "    for i in range(1, len(decreased_data)):\n",
    "        if decreased_data[i] > decreased_data[i - 1]:\n",
    "            decreased_data[i] = decreased_data[i - 1]\n",
    "    return decreased_data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dee336f6df8eed71"
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "812474b0db577fb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.530111Z",
     "start_time": "2023-11-12T22:22:11.458390Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(raw_data, decreasing_data):\n",
    "    \"\"\"\n",
    "    Plot the raw, smoothed, and decreasing step-like weight data in separate subplots sharing the x-axis.\n",
    "\n",
    "    Parameters:\n",
    "    - raw_data (np.ndarray): The raw weight data array.\n",
    "    - smoothed_data (np.ndarray): The smoothed weight data array.\n",
    "    - decreasing_data (np.ndarray): The decreasing step-like weight data array.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "    \n",
    "    # Raw data plot\n",
    "    axs[0].plot(raw_data, label='Raw Data', alpha=0.5, color='green')\n",
    "    axs[0].set_title('Raw Weight Data')\n",
    "    axs[0].set_ylabel('Weight (grams)')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # # Smoothed data plot\n",
    "    # axs[1].plot(smoothed_data, label='Smoothed Data', color='orange')\n",
    "    # axs[1].set_title('Smoothed Weight Data')\n",
    "    # axs[1].set_ylabel('Weight (grams)')\n",
    "    # axs[1].legend()\n",
    "\n",
    "    # Decreasing step-like data plot\n",
    "    axs[1].plot(decreasing_data, label='Decreasing Step-like Data', color='red')\n",
    "    axs[1].set_title('Decreasing Step-like Weight Data')\n",
    "    axs[1].set_xlabel('Time (arbitrary units)')\n",
    "    axs[1].set_ylabel('Weight (grams)')\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "outputs": [],
   "source": [
    "def calculate_bite_sizes(decreasing_data, threshold=4):\n",
    "    \"\"\"\n",
    "    Calculate the number of bites and the weight of each bite from the decreasing step-like weight data,\n",
    "    considering only those bites where the weight decrease is greater than a specified threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - decreasing_data (np.ndarray): The decreasing step-like weight data array.\n",
    "    - threshold (int): The minimum weight decrease to qualify as a bite.\n",
    "\n",
    "    Returns:\n",
    "    - int: The number of bites.\n",
    "    - list: The list of weights for each qualified bite.\n",
    "    \"\"\"\n",
    "    bite_sizes = []\n",
    "    for i in range(1, len(decreasing_data)):\n",
    "        if decreasing_data[i] < decreasing_data[i - 1]:\n",
    "            bite_size = decreasing_data[i - 1] - decreasing_data[i]\n",
    "            if bite_size >= threshold:\n",
    "                bite_sizes.append(bite_size)\n",
    "    \n",
    "    number_of_bites = len(bite_sizes)\n",
    "    return number_of_bites, bite_sizes\n",
    "\n",
    "# You would then call this function as before in the main function.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.530459Z",
     "start_time": "2023-11-12T22:22:11.462510Z"
    }
   },
   "id": "738a061597f9c8f2"
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "def calculate_bite_sizes_advanced(decreasing_data, threshold=4, window_length=21, polyorder=3):\n",
    "    \"\"\"\n",
    "    Advanced calculation of the number of bites and the weight of each bite using signal processing\n",
    "    techniques to detect the local minima in the smoothed signal.\n",
    "\n",
    "    Parameters:\n",
    "    - decreasing_data (np.ndarray): The decreasing step-like weight data array.\n",
    "    - threshold (int): The minimum weight decrease to qualify as a bite.\n",
    "    - window_length (int): The length of the filter window (number of coefficients). Must be a positive odd integer.\n",
    "    - polyorder (int): The order of the polynomial used to fit the samples. Must be less than `window_length`.\n",
    "\n",
    "    Returns:\n",
    "    - int: The number of bites.\n",
    "    - list: The list of weights for each qualified bite.\n",
    "    \"\"\"\n",
    "    # Apply a Savitzky-Golay filter to the data to smooth it while preserving peaks\n",
    "    smoothed_data = savgol_filter(decreasing_data, window_length=window_length, polyorder=polyorder, mode='interp')\n",
    "\n",
    "    # Compute the first derivative of the smoothed data\n",
    "    derivative = np.diff(smoothed_data, n=1)\n",
    "    \n",
    "    # Find peaks (local minima) in the negative derivative (which correspond to bites in the original data)\n",
    "    peaks, _ = find_peaks(-derivative, height=-threshold)\n",
    "\n",
    "    # Calculate bite sizes based on the peaks detected\n",
    "    bite_sizes = np.diff(peaks, prepend=0)\n",
    "    \n",
    "    # Filter out the consecutive bites that are too close to each other, if necessary\n",
    "    # This step is optional and can be customized based on domain knowledge\n",
    "    \n",
    "    number_of_bites = len(bite_sizes)\n",
    "    return number_of_bites, bite_sizes.tolist()\n",
    "\n",
    "# You would call this function in your main function after processing the data.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.530489Z",
     "start_time": "2023-11-12T22:22:11.466227Z"
    }
   },
   "id": "813a7454e08bf71e"
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bites simple: 49\n",
      "Weight of each bite simple: [27, 4, 9, 4, 20, 6, 13, 4, 11, 4, 8, 13, 13, 10, 12, 16, 13, 7, 15, 14, 6, 9, 18, 12, 8, 4, 8, 13, 11, 23, 6, 14, 11, 13, 20, 5, 7, 14, 7, 4, 5, 5, 15, 10, 7, 5, 11, 4, 4]\n",
      "Number of bites advanced: 130\n",
      "Weight of each bite advanced: [8, 3, 3, 15, 3, 3, 3, 7, 2, 3, 3, 9, 3, 3, 2, 3, 3, 3, 2, 3, 3, 7, 3, 3, 4, 3, 6, 3, 3, 5, 3, 5, 3, 4, 3, 4, 3, 3, 4, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 2, 3, 3, 7, 4, 3, 12, 3, 4, 5, 3, 2, 3, 5, 4, 3, 3, 3, 3, 4, 3, 5, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 4, 3, 11, 3, 3, 3, 7, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 6, 3, 2, 3, 3, 3, 14, 3, 3, 4, 5, 3, 10, 3, 3, 3, 3, 13, 3, 3, 7, 3, 4, 2, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = '../data/raw/17'\n",
    "\n",
    "# Load the raw data\n",
    "weights = load_data(path).to_numpy()\n",
    "window_size = 5\n",
    "# smoothed_weights = moving_average(weights, window_size)\n",
    "decreasing_data = create_decreasing_curve(weights)\n",
    "trimmed_raw_weights = weights[window_size - 1:]\n",
    "number_of_bites, bite_sizes = calculate_bite_sizes(decreasing_data,4)\n",
    "\n",
    "print(f\"Number of bites simple: {number_of_bites}\")\n",
    "print(f\"Weight of each bite simple: {bite_sizes}\")\n",
    "# plot(trimmed_raw_weights, decreasing_data\n",
    "\n",
    "adv_number_of_bites, adv_bite_sizes = calculate_bite_sizes_advanced(decreasing_data, 2, 7, 5)\n",
    "\n",
    "print(f\"Number of bites advanced: {adv_number_of_bites}\")\n",
    "print(f\"Weight of each bite advanced: {adv_bite_sizes}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.530572Z",
     "start_time": "2023-11-12T22:22:11.469209Z"
    }
   },
   "id": "a8cb273e7fb7a270"
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "26251016cd09875c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T22:22:11.530600Z",
     "start_time": "2023-11-12T22:22:11.473266Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
